{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-my-portfolio-page","title":"Welcome to the My Portfolio Page","text":"<p>For full list of projects and repositories visit: My GitHub Profile.</p>"},{"location":"#my-social-media-links","title":"My Social Media Links","text":"<ul> <li>LinkedIn </li> <li>facebook</li> <li>twitter/x</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<ul> <li>My Project related to ML &amp; AI are under Projects</li> </ul>"},{"location":"about/","title":"About","text":""},{"location":"about/#about-me","title":"About Me","text":"<p>Welcome to my world of data and innovation! \ud83d\ude80 I am a passionate Data Scientist/Data Engineer/ML Engineer </p>"},{"location":"about/#my-journey","title":"My Journey \ud83c\udf0d","text":"<p>I have an extensive experience of over 25 years in the field of datawarehousing/ data analytics/ machine learning/ data science. Insatiable intellectual curiosity and ability to mine hidden gems located within large sets of structured, semi-structured, and raw data.</p> <p>Have an overall 25 years of experience working with Teradata. Extensive hands-on experience Teradata performance and Query optimization, Teradata ecosystem components like data mover, Query Grid, Teradata data migration engagements, teradataml/ ClearScape. I have been in providing Teradata backup solutions to Teradata customers. Also, extensive experience on various Unix &amp; Linux platforms running Teradata systems and other supporting systems as well as extensive experience on shell scripting.  I\u2019m also actively building my skillset on various ML projects using regression, classification &amp; deep learning using scikit-learn, TensorFlow to further enhance my skills in ML side of thing.  Hands on experience building RAG &amp; LLM based apps using python streamlit, Django, various Ollama models &amp; hugging face models.</p>"},{"location":"blogs/","title":"Blogs","text":"<p>Coming soon...Please stay tuned! </p>"},{"location":"projects/","title":"Here are some of the projects:","text":""},{"location":"projects/#personal-portfolio-using-mkdocs","title":"personal portfolio using mkdocs","text":"<p>Description: Created my portfolio website using python framework mkdocs.</p> <p>Project_1</p>"},{"location":"projects/#local-llm-to-help-answer-user-questions-from-provided-textpdfdoc-files","title":"Local LLM to help answer user questions from provided text/PDF/doc files","text":"<p>Description:   Created RAG based app using Ollama model llama3 that takes test/PDF/doc file as an input   using streamlit GUI. Project_2</p>"},{"location":"projects/#classification-using-deeplearning","title":"Classification using deeplearning","text":"<p>Description: The non-profit foundation Alphabet Soup wants to create an algorithm to predict whether or not applicants for funding will be successful. With your knowledge of machine learning and neural networks, use the features in the provided dataset to create a binary classifier that is capable of predicting whether applicants will be successful if funded by Alphabet Soup. From Alphabet Soup\u2019s business team, you have received a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years Project_3</p>"},{"location":"projects/#credit-risk-evaluator-using-logistic-regression-random-forest","title":"credit risk evaluator using logistic regression &amp; random forest","text":"<p>Description: This project involves analyzing and predicting a provided dataset of loan applicants to evaluate &amp; predict the risk involved in loan approval. Project_4</p>"},{"location":"resume/","title":"\ud83d\udcc4 My Resume","text":""},{"location":"resume/#about-me","title":"\ud83d\udc68\u200d\ud83d\udcbb About Me","text":"<p>Hi, I'm Nawaz Y. khan! A passionate Data Analyst/Data Scientist/ML Engineer with expertise in turning data into actionable insights. I thrive on solving complex problems and delivering data-driven solutions.</p> <ul> <li>\ud83d\udccd Location: Birmingham, UK</li> <li>\ud83d\udce7 Email: nawazyarkhan@gmail.com</li> <li>\ud83c\udf10 Portfolio: github.io/nawazyarkhan</li> <li>\ud83d\udcbc LinkedIn: www.linkedIn.com/nawaz-yar-khan</li> </ul>"},{"location":"resume/#education","title":"\ud83c\udf93 Education","text":"<ul> <li> <p>[B.Sc Electrical Engineering]     \ud83d\udccd University of Engineering &amp; Technology Lahore, PK 1998  </p> <ul> <li>Relevant Courses: Electrical &amp; communications</li> </ul> </li> <li> <p>[PostGrad Diploma in Data Analytics]     \ud83d\udccd University of Birmingham, 2021  </p> <ul> <li>Relevant Courses: Data analytics/ ML</li> </ul> </li> </ul>"},{"location":"resume/#work-experience","title":"\ud83d\udcbc Work Experience","text":""},{"location":"resume/#ps-consultant","title":"PS Consultant","text":"<p>\ud83d\udccd Teradata UK Pvt Limited, Jun2022 - Present   \ud83d\udd39  LLOYDS data migration Project \u2013 I have been actively involved with the data migration project using various data migration related tasks. I have been tasked to optimize queries involved in using big tables where I have managed to optimize by changing the table DDLs and optimizing queries which helped to reduce the CPU &amp; IO.                                                                                  </p> <p>\ud83d\udd39  HSBC Cloud Project \u2013 I have been tasked to configure the Query Grid in the cloud. HSBC has got multiple systems both on-prem &amp; cloud making it one of the most complex configurations and I have been able to successfully configure &amp; test the QueryGrid. Also, I have been given the task to configure the data mover across 5 systems in cloud. </p> <p>\ud83d\udd39  BOI Security hardening project \u2013 I have been tasked for OS security hardening which is one of the Teradata PS engagements and have successfully completed it across their PROD &amp; DR systems. </p> <p>\ud83d\udd39  LLOYDS Data Mover &amp; Viewpoint DR test project - I have managed a project for a failover test of viewpoint &amp; data mover to simulate a DR exercise which I have completed smoothly. </p> <p>\ud83d\udd39  LLOYDS security hardening project \u2013 I have been involved actively in addressing various security issues identified in the security penetration test across all their systems estate.</p> <p>\ud83d\udd39  PTSB Datamover framework setup project - Worked on Datamover setup project in PTSB to help automate the datamover jobs to sync data from production site to DR site.</p> <p>\ud83d\udd39  Admiral Data Migration project \u2013 I have been involved with the data migration project to cloud system using data mover. Also, have successfully setup the LDAP on cloud system.</p>"},{"location":"resume/#data-migrations-technical-team-lead","title":"Data Migrations technical Team lead","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Dec2020 \u2013 Jun2022    \ud83d\udd39 I have been promoted as team lead of the team providing consultancy/pre-sales support and  implementations of data migrations. As a team lead, I\u2019m acting as technical mentor for the team, doing the project assignments as well as handling complex migration projects in the EMEA region. Currently focused on doing migrations from on-prem to cloud systems which is in line with focus of moving to cloud. </p>"},{"location":"resume/#data-migration-bar-consultant","title":"Data Migration/ BAR consultant","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Aug2018 - Dec2020    \ud83d\udd39 I have been promoted as team lead of the team providing consultancy/pre-sales support and  implementations of data migrations. As a team lead, I\u2019m acting as technical mentor for the team, doing the project assignments as well as handling complex migration projects in the EMEA region. Currently focused on doing migrations from on-prem to cloud systems which is in line with focus of moving to cloud. </p>"},{"location":"resume/#change-control-specialist","title":"Change Control Specialist","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Jul2016 - Aug2018    \ud83d\udd39 I've worked as part of the regional International Change control team as a change control specialist who is responsible for all major/minor Teradata upgrades/configuration changes/expansion etc in the International Region (UK/Europe, Middle East/Africa/Asia Pacific etc) . I have also been involved with Hadoop upgrades. </p>"},{"location":"resume/#senior-systems-engineer-technical-account-manager","title":"Senior Systems Engineer / Technical Account Manager","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Mar2011 - Jul2016   \ud83d\udd39 I have been involved with Minor, Major Teradata upgrades, and Teradata hardware    expansions/merge activities. I have an extensive hardware &amp; software support experience on  66xx, 67xx, 27xx, 2800, 52xx, 53xx, 54xx, 55xx, 56xx, 66xx, 26xx, 25xx, etc. &amp; various LSI  platforms 684x.Also, have an extensive hands-on experience on ECO systems (TMSM, Viewpoint and Datamover) upgrades.</p>"},{"location":"resume/#senior-systems-engineer-technical-team-lead","title":"Senior Systems Engineer / Technical Team Lead","text":"<p>\ud83d\udccd NCR/Teradata Corporation, Pakistan   Sep2000 - Mar2011   \ud83d\udd39I have worked as \u201cSenior Systems Engineer/Technical Team lead\u201d based in Lahore providing onsite support to critical customers as well as remote support/2nd level of support to the local team of CSRs on various support calls. During tenure of last 11 years, I have done many critical installations/expansions/upgrades of DWH systems at various customer sites like Mobilink DWH, Bank Alfalah DWH, Ufone DWH, ACBL DWH, ITDPunjab DWH, RBL DWH, ZTE-PTCL DWH, Telenor DWH, &amp; Telenor and Bahria Town Call Centers. I have also been involved with the Netvault/Netbackup installation &amp; configuration, ACSLS, Storagetek tape libraries like L180, SL500 at various sites in Pakistan. Have successfully done the netvault Installation, SAN switch configuration at one of the biggest customers in Pakistan (Mobilink). Have also done a data migration using tapes in a netvault environment in Bank Alfalah Karachi Pakistan.  </p>"},{"location":"resume/#skills","title":"\ud83d\udee0\ufe0f Skills","text":"<ul> <li>Exploratory data analysis (EDA)</li> <li>Python (Dataframes, NumPy) / Machine learning / deep learning (scikit learn, TensorFlow) </li> <li>Visualization tools  - Tableau, Matplotlib, Seaborn, Plotly </li> <li>MLOps </li> <li>Web scraping </li> <li>LLM &amp; RAG based models &amp; building AI agents</li> <li>Django framework</li> <li>SUSE Linux/shell scripting, OS Security hardening</li> <li>Teradata BAR solution (Netbackup/DSA)</li> <li>Teradata Query &amp; database performance optimization</li> <li>Teradata QG &amp; Data mover configuration </li> <li>DTU &amp; NPARC DMS tool (TD internal developed for data migrations), NetBackup, Netvault</li> </ul>"},{"location":"resume/#certifications-professional-courses","title":"\ud83c\udfc6 Certifications &amp; Professional Courses","text":"<ul> <li>Supervised Machine Learning: Regression and Classification from Coursera</li> <li>Advanced Learning Algorithms from Coursera</li> <li>Unsupervised Learning, Recommenders, Reinforcement Learning from Coursera</li> <li>Data Science and AI Mentorship Program (DSAAMP) from codanics.com</li> <li>Data analytics boot camp University of Birmingham</li> <li>Vantage Associate 2.3 Certified</li> <li>Vantage cloud lake certified associate</li> <li>Vantage Administration Certified </li> <li>Vantage Data engineering certified </li> <li>Teradata\u2019s Internal Architecture Foundation program (Mar\u2019 24 \u2013 Jan\u2019 25) \u2013 I have been selected across the globe along with a group of selected people who are being trained on architecture foundation program involving developing skills on new technologies and various hands-on activities &amp; presentations to help develop the skills for a prospect solution architect. </li> <li>Teradata Certified Master </li> <li>Teradata Certified support associate</li> <li>Amazon AWS certified solution architect \u2013 Associate </li> </ul>"},{"location":"resume/#interests","title":"\ud83c\udf1f Interests","text":"<ul> <li>\ud83d\udcc8 Data Storytelling  </li> <li>\ud83e\udd16 Artificial Intelligence  </li> <li>\ud83c\udf0d Open Source Contributions  </li> <li>\ud83d\udcda Continuous Learning  </li> </ul>"},{"location":"resume/#contact-me","title":"\ud83d\udcec Contact Me","text":"<p>Feel free to reach out via email or connect with me on LinkedIn!</p>"},{"location":"skills/","title":"My Skillset","text":"<ul> <li>Exploratory data analysis (EDA)</li> <li>Python (Dataframes, NumPy) / Machine learning / deep learning (scikit learn, TensorFlow) </li> <li>Visualization tools  - Tableau, Matplotlib, Seaborn, Plotly </li> <li>MLOps </li> <li>Web scraping </li> <li>LLM &amp; RAG based models &amp; building AI agents</li> <li>Django framework</li> <li>SUSE Linux/shell scripting, OS Security hardening</li> <li>Teradata BAR solution (Netbackup/DSA)</li> <li>Teradata Query &amp; database performance optimization</li> <li>Teradata QG &amp; Data mover configuration </li> <li>DTU &amp; NPARC DMS tool (TD internal developed for data migrations), NetBackup, Netvault</li> </ul>"}]}