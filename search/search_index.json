{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-my-portfolio-page","title":"Welcome to My Portfolio Page","text":"<p>For full list of projects and repositories visit: My GitHub Profile.</p>"},{"location":"#my-social-media-links","title":"My Social Media Links","text":"<ul> <li>LinkedIn </li> <li>facebook</li> <li>twitter/x</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<ul> <li>My Projects related to Python, ML/AI are under Projects</li> </ul>"},{"location":"about/","title":"About","text":""},{"location":"about/#about-me","title":"About Me","text":"<p>Welcome to my world of data and innovation! \ud83d\ude80 I am a passionate Data Scientist/Data Engineer/ML Engineer </p>"},{"location":"about/#my-journey","title":"My Journey \ud83c\udf0d","text":"<p>I have an extensive experience of over 25 years in the field of datawarehousing/ data analytics/ machine learning/ data science. Insatiable intellectual curiosity and ability to mine hidden gems located within large sets of structured, semi-structured, and raw data.</p> <p>Have an overall 25 years of experience working with Teradata. Extensive hands-on experience Teradata performance and Query optimization, Teradata ecosystem components like data mover, Query Grid, Teradata data migration engagements, teradataml/ ClearScape. I have been in providing Teradata backup solutions to Teradata customers. Also, extensive experience on various Unix &amp; Linux platforms running Teradata systems and other supporting systems as well as extensive experience on shell scripting.  I\u2019m also actively building my skillset on various ML projects using regression, classification &amp; deep learning using scikit-learn, TensorFlow to further enhance my skills in ML side of thing.  Hands on experience building RAG &amp; LLM based apps using python streamlit, Django, various Ollama models &amp; hugging face models.</p>"},{"location":"blogs/","title":"Blogs","text":""},{"location":"blogs/#posts","title":"Posts","text":"<ul> <li>A Practical Guide to Large Language Models (LLMs) \u2014 Strengths &amp; Best Uses</li> </ul> <p>More posts will be added here as I publish them.</p>"},{"location":"projects/","title":"Summary of Projects:","text":""},{"location":"projects/#projects-done-as-ai-resident-egineer-in-apziva","title":"Projects done as AI resident Egineer in Apziva","text":""},{"location":"projects/#term-desposit-subscription","title":"Term desposit subscription","text":"<p>Description: \uf0a7 Built an end-to-end machine learning pipeline to predict term-deposit subscriptions, achieving ~96% model accuracy using CatBoost after evaluating multiple classification algorithms. Performed full data preprocessing, cleaning, EDA, and feature engineering. Optimized model performance through cross-validation, hyperparameter tuning, and algorithm comparison. Generated actionable feature-importance insights to identify key customer behaviour drivers and support targeted marketing strategies. Conducted statistical analysis and customer segmentation to discover high-conversion customer groups and improve marketing decision-making.  Delivered a reproducible workflow with modular, well-documented Python code, supporting scalability and future deployment Project details on my github repository https://github.com/nawazyarkhan/TermDepositMarketing</p>"},{"location":"projects/#customer-behaviour-prediction-in-a-logisticsdelivery-domain","title":"Customer behaviour prediction in a logistics/delivery domain","text":"<p>Description: Developed a machine learning solution to predict customer satisfaction for a logistics startup, improving prediction accuracy to ~73% by performing data preprocessing, EDA, feature engineering, and model optimization using scikit-learn, and delivering insights that enhanced customer retention strategies. project details/code can be found in my github repository https://github.com/nawazyarkhan/HappyCustomerLogistics</p>"},{"location":"projects/#projects-done-as-part-of-engagement-in-codanics","title":"Projects done as part of engagement in codanics","text":""},{"location":"projects/#personal-portfolio-using-mkdocs","title":"Personal portfolio using mkdocs","text":"<p>Description: Created my portfolio website using python framework mkdocs. project details/code can be found in my github repository https://github.com/nawazyarkhan/myportfolio</p>"},{"location":"projects/#sample-portfolio-using-django","title":"Sample portfolio using DJANGO","text":"<p>Description: Created my sample portfolio website using python framework DJANGO. project details/code can be found in my github repository https://github.com/nawazyarkhan/nykPortfolio</p>"},{"location":"projects/#local-llm-to-help-answer-user-questions-from-provided-textpdfdoc-files","title":"Local LLM to help answer user questions from provided text/PDF/doc files","text":"<p>Description:   Created RAG based app using Ollama model llama3 that takes test/PDF/doc file as an input   using streamlit GUI.   Details can be found under github repository https://github.com/nawazyarkhan/localRAG_AI</p>"},{"location":"projects/#classification-using-deeplearning","title":"Classification using deeplearning","text":"<p>Description: The non-profit foundation Alphabet Soup wants to create an algorithm to predict whether or not applicants for funding will be successful. With your knowledge of machine learning and neural networks, use the features in the provided dataset to create a binary classifier that is capable of predicting whether applicants will be successful if funded by Alphabet Soup. From Alphabet Soup\u2019s business team, you have received a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. Details/code can be found under github repository https://github.com/nawazyarkhan/DeepLearningHomeWork</p>"},{"location":"projects/#comparison-of-various-classification-algorithms-codanics","title":"comparison of various classification algorithms @codanics","text":"<p>Description: This is a comparison of different classification algorithms (decision tree, random forest, XGBoost) performance using the diamonds dataset from seaborn. Details/code can be found under github repository https://github.com/nawazyarkhan/classification_algorithms_comparison</p>"},{"location":"projects/#projects-done-during-the-course-at-uob","title":"Projects done during the course at UOB","text":""},{"location":"projects/#credit-risk-evaluator-using-logistic-regression-random-forest","title":"Credit risk evaluator using logistic regression &amp; random forest","text":"<p>Description: This project involves analyzing and predicting a provided dataset of loan applicants to evaluate &amp; predict the risk involved in loan approval. Details/code can be found under my github repository https://github.com/nawazyarkhan/SupervisedMachineLearningHomework</p>"},{"location":"resume/","title":"\ud83d\udcc4 My Resume","text":""},{"location":"resume/#about-me","title":"\ud83d\udc68\u200d\ud83d\udcbb About Me","text":"<p>Hi, I'm Nawaz Y. khan! A passionate Data Engineer/Data Scientist/ML Engineer with expertise in turning data into actionable insights. I thrive on solving complex problems and delivering data-driven solutions.</p> <ul> <li>\ud83d\udccd Location: Birmingham, UK</li> <li>\ud83d\udce7 Email: nawazyarkhan@gmail.com</li> <li>\ud83c\udf10 Portfolio: github.io/nawazyarkhan</li> <li>\ud83d\udcbc LinkedIn: www.linkedIn.com/nawaz-yar-khan</li> </ul>"},{"location":"resume/#education","title":"\ud83c\udf93 Education","text":"<ul> <li> <p>[B.Sc Electrical Engineering]     \ud83d\udccd University of Engineering &amp; Technology Lahore, PK 1998  </p> <ul> <li>Relevant Courses: Electrical &amp; communications</li> </ul> </li> <li> <p>[PostGrad Diploma in Data Analytics]     \ud83d\udccd University of Birmingham, 2021  </p> <ul> <li>Relevant Courses: Data analytics/ ML</li> </ul> </li> </ul>"},{"location":"resume/#work-experience","title":"\ud83d\udcbc Work Experience","text":""},{"location":"resume/#ai-resident-engineer","title":"AI Resident Engineer","text":"<p>\ud83d\udccd Apziva, Nov2025 - Present  </p> <p>\ud83d\udd39  Built an end-to-end machine learning pipeline to predict term-deposit subscriptions, achieving ~96% model accuracy using CatBoost after evaluating multiple classification algorithms. Performed full data preprocessing, cleaning, EDA, and feature engineering. Optimized model performance through cross-validation, hyperparameter tuning, and algorithm comparison. Generated actionable feature-importance insights to identify key customer behaviour drivers and support targeted marketing strategies. Conducted statistical analysis and customer segmentation to discover high-conversion customer groups and improve marketing decision-making.  Delivered a reproducible workflow with modular, well-documented Python code, supporting scalability and future deployment. </p> <p>\ud83d\udd39   Exceeded project deadline by 3 days for a machine learning solution to predict customer satisfaction for a logistics startup, improving prediction accuracy to ~73% by performing data preprocessing, EDA, feature engineering, and model optimisation using scikit-learn, and delivering insights that enhanced customer retention strategies. </p>"},{"location":"resume/#ps-consultant","title":"PS Consultant","text":"<p>\ud83d\udccd Teradata UK Pvt Limited, Jun2022 - Oct2025  </p> <p>\ud83d\udd39  Reduced customer costs significantly and execution time by &gt;50%, optimising SQL queries to run faster, enhancing system efficiency and decreasing resource usage significantly. CPU &amp; I/O reduced by 1/10th or less.</p> <p>\ud83d\udd39  Optimised complex backup/restore setups, reduced system outages by up to 50%+, significantly enhancing customer satisfaction through fine-tuning OS/application parameters in line with customer needs and environment.</p> <p>\ud83d\udd39  Contributed to various data migration and security hardening projects for key clients in UK, including Lloyds, HSBC, Bank of Ireland, and Admiral.</p> <pre><code>o   Participated in a query optimization activity, reducing CPU and IO, optimising queries and changing DDLs.\n\no   Completed successful time-critical QueryGrid migration to the cloud, improved operational efficiency, reduced 5-6 days for the customer\u2019s DBA team through configuring and validating the Data Mover across 5 cloud environments.\n\no   Achieved rapid and reliable OS security hardening across both production and disaster recovery environments, leading the initiative by implementing automated scripts for a consistent control application.\n\no   Managed a smooth and effective failover test for Viewpoint and Data Mover, as part of a disaster recovery exercise through planning, coordinating, and executing the full tests, ensuring all components and dependencies were aligned correctly and monitored throughout.\n</code></pre>"},{"location":"resume/#data-migrations-technical-team-lead","title":"Data Migrations technical Team lead","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Dec2020 \u2013 Jun2022</p> <p>\ud83d\udd39 Reduced downtime by 25-30% and enhanced system       availability for complex migrations by implementing innovative optimisations during the planning and test phase and achieving substantial customer cost savings.        o Won the Excellence Award for 2021 Q1 as the project set a standard, helping sales to secure other customers for cloud migrations. </p> <p>\ud83d\udd39Mentored team members in migrations, significantly enhancing efficiency and reducing resource wastage through expert guidance and support in challenging situations</p> <p>\ud83d\udd39Promoted to team lead for a team of 3 handling migrations   in EMEA region, technical mentor providing training and guidance, handling project assignments, and complex migration projects (On-prem to Cloud).</p>"},{"location":"resume/#data-migration-bar-consultant","title":"Data Migration/ BAR consultant","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Aug2018 - Dec2020</p> <p>\ud83d\udd39 Considered best DMS consultant with a proven record in migrations with no or minimal issues/disruptions and within or before customer agreed timelines. </p> <p>\ud83d\udd39 Supported Sales/Presales in selling the migration and BAR by for BAR, it is proposing and implementing a solution that best suits customer needs according to their system data size, their backup/restore time window requirements (RTO/RPO). </p> <p>\ud83d\udd39 Delivered fluid and error-free data critical customer migrations across various locations across EMEA.</p>"},{"location":"resume/#change-control-specialist","title":"Change Control Specialist","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Jul2016 - Aug2018 </p> <p>\ud83d\udd39 Implemented major Teradata upgrades/system expansions on time with minimal data disruption as part of the International Region, including UK/Europe, Middle East/Africa/Asia Pacific. </p> <p>\ud83d\udd39Exceeded established customer expectations by determining the correct planning/preparation and resources were in place. </p> <p>\ud83d\udd39Worked on upgrades for the Ministry of Defence (MOD), chosen as a select team, requiring SC clearance and working in a very controlled environment.  </p>"},{"location":"resume/#senior-systems-engineer-technical-account-manager","title":"Senior Systems Engineer / Technical Account Manager","text":"<p>\ud83d\udccd Teradata UK Pvt Limited      Mar2011 - Jul2016  </p> <p>\ud83d\udd39 I have been involved with Minor, Major Teradata upgrades, and Teradata hardware    expansions/merge activities. I have an extensive hardware &amp; software support experience on  66xx, 67xx, 27xx, 2800, 52xx, 53xx, 54xx, 55xx, 56xx, 66xx, 26xx, 25xx, etc. &amp; various LSI  platforms 684x.Also, have an extensive hands-on experience on ECO systems (TMSM, Viewpoint and Datamover) upgrades.</p>"},{"location":"resume/#senior-systems-engineer-technical-team-lead","title":"Senior Systems Engineer / Technical Team Lead","text":"<p>\ud83d\udccd NCR/Teradata Corporation, Pakistan   Sep2000 - Mar2011 </p> <p>\ud83d\udd39I have worked as \u201cSenior Systems Engineer/Technical Team lead\u201d based in Lahore providing onsite support to critical customers as well as remote support/2nd level of support to the local team of CSRs on various support calls. During tenure of last 11 years, I have done many critical installations/expansions/upgrades of DWH systems at various customer sites like Mobilink DWH, Bank Alfalah DWH, Ufone DWH, ACBL DWH, ITDPunjab DWH, RBL DWH, ZTE-PTCL DWH, Telenor DWH, &amp; Telenor and Bahria Town Call Centers. I have also been involved with the Netvault/Netbackup installation &amp; configuration, ACSLS, Storagetek tape libraries like L180, SL500 at various sites in Pakistan. Have successfully done the netvault Installation, SAN switch configuration at one of the biggest customers in Pakistan (Mobilink). Have also done a data migration using tapes in a netvault environment in Bank Alfalah Karachi Pakistan.  </p>"},{"location":"resume/#skills","title":"\ud83d\udee0\ufe0f Skills","text":"<ul> <li>Exploratory data analysis (EDA)</li> <li>Python (Dataframes, NumPy) / Machine learning / deep learning (scikit learn, TensorFlow) </li> <li>Visualization tools  - Tableau, Matplotlib, Seaborn, Plotly </li> <li>MLOps </li> <li>Web scraping </li> <li>LLM &amp; RAG based models &amp; building AI agents</li> <li>Django framework</li> <li>SUSE Linux/shell scripting, OS Security hardening</li> <li>Teradata BAR solution (Netbackup/DSA)</li> <li>Teradata Query &amp; database performance optimization</li> <li>Teradata QG &amp; Data mover configuration </li> <li>DTU &amp; NPARC DMS tool (TD internal developed for data migrations), NetBackup, Netvault</li> </ul>"},{"location":"resume/#certifications-professional-courses","title":"\ud83c\udfc6 Certifications &amp; Professional Courses","text":"<ul> <li>Supervised Machine Learning: Regression and Classification from Coursera</li> <li>Advanced Learning Algorithms from Coursera</li> <li>Unsupervised Learning, Recommenders, Reinforcement Learning from Coursera</li> <li>Data Science and AI Mentorship Program (DSAAMP) from codanics.com</li> <li>Data analytics boot camp University of Birmingham</li> <li>Vantage Associate 2.3 Certified</li> <li>Vantage cloud lake certified associate</li> <li>Vantage Administration Certified </li> <li>Vantage Data engineering certified </li> <li>Teradata\u2019s Internal Architecture Foundation program (Mar\u2019 24 \u2013 Jan\u2019 25) \u2013 I have been selected across the globe along with a group of selected people who are being trained on architecture foundation program involving developing skills on new technologies and various hands-on activities &amp; presentations to help develop the skills for a prospect solution architect. </li> <li>Teradata Certified Master </li> <li>Teradata Certified support associate</li> <li>Amazon AWS certified solution architect \u2013 Associate </li> </ul>"},{"location":"resume/#interests","title":"\ud83c\udf1f Interests","text":"<ul> <li>\ud83d\udcc8 Data Storytelling  </li> <li>\ud83e\udd16 Artificial Intelligence  </li> <li>\ud83c\udf0d Open Source Contributions  </li> <li>\ud83d\udcda Continuous Learning  </li> </ul>"},{"location":"resume/#contact-me","title":"\ud83d\udcec Contact Me","text":"<p>Feel free to reach out via email or connect with me on LinkedIn!</p>"},{"location":"skills/","title":"My Skillset","text":"<ul> <li>Exploratory data analysis (EDA)</li> <li>Python (Dataframes, NumPy) / Machine learning / deep learning (scikit learn, TensorFlow) </li> <li>Visualization tools  - Tableau, Matplotlib, Seaborn, Plotly </li> <li>MLOps </li> <li>Web scraping </li> <li>LLM &amp; RAG based models &amp; building AI agents</li> <li>Django framework</li> <li>SUSE Linux/shell scripting, OS Security hardening</li> <li>Teradata BAR solution (Netbackup/DSA)</li> <li>Teradata Query &amp; database performance optimization</li> <li>Teradata QG &amp; Data mover configuration </li> <li>DTU &amp; NPARC DMS tool (TD internal developed for data migrations), NetBackup, Netvault</li> </ul>"},{"location":"blogs/llm-guide/","title":"A Practical Guide to Large Language Models (LLMs) \u2014 Strengths &amp; Best Uses","text":"<p>This post compares major LLM families (OpenAI GPT, Anthropic Claude, Google Gemini/PaLM, Meta Llama, Mistral, Falcon/MPT, and other alternatives), explains their strengths and weaknesses, and recommends which to choose for chat assistants, code, RAG, on-device inference, and cost-sensitive workflows.</p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#why-this-guide","title":"Why this guide","text":"<ul> <li>Inputs: You need to pick an LLM for a concrete task (chatbot, summarization, code assistant, RAG, or self-hosting).</li> <li>Outputs: Short list of recommended models, strengths/weaknesses, example prompts, and a quick decision checklist.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#model-by-model-guide","title":"Model-by-model guide","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#openai-gpt-4-gpt-35","title":"OpenAI \u2014 GPT-4 / GPT-3.5","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths","title":"Strengths","text":"<ul> <li>Best-in-class instruction following, reasoning, and code generation.</li> <li>Rich SDKs, plugins, and production-ready tooling.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses","title":"Weaknesses","text":"<ul> <li>Higher cost and vendor lock-in.</li> <li>Data residency and privacy concerns for sensitive data.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses","title":"Best uses","text":"<ul> <li>Production chat assistants that need tool use and high reliability.</li> <li>High-quality summarization, content generation, and RAG generation.</li> <li>Code completion, refactoring, and developer tooling.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt","title":"Example prompt","text":"<p>\"Summarize the following text in 5 bullets focusing on action items and risks:\"</p> <pre><code>The product launch was delayed three weeks due to supplier shortages. The engineering team recommends increasing vendor redundancy and adding a safety stock. Marketing timelines will shift and customer communications must be prepared. The finance team should review budget for expedited shipping options.\n</code></pre>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#anthropic-claude","title":"Anthropic \u2014 Claude","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_1","title":"Strengths","text":"<ul> <li>Safety-by-design and robust instruction following in long dialogues.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses_1","title":"Weaknesses","text":"<ul> <li>Responses can be conservative; smaller community ecosystem than OpenAI.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_1","title":"Best uses","text":"<ul> <li>Customer support assistants and internal knowledge-base chatbots where safety is essential.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_1","title":"Example prompt","text":"<p>\"You are a helpful, cautious assistant. If you are unsure, say what data you'd need to be certain.\"</p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#google-palm-gemini","title":"Google \u2014 PaLM / Gemini","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_2","title":"Strengths","text":"<ul> <li>Strong multimodal capabilities and integration with Google Cloud services.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses_2","title":"Weaknesses","text":"<ul> <li>Ecosystem lock-in and variable pricing models.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_2","title":"Best uses","text":"<ul> <li>Multimodal applications (image+text) and enterprises already using GCP.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_2","title":"Example prompt","text":"<p>\"Analyze the attached image and list three business insights with supporting evidence from the image.\" </p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#meta-llama-2-3","title":"Meta \u2014 Llama (2 / 3)","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_3","title":"Strengths","text":"<ul> <li>Open weights, suitable for fine-tuning and on-prem self-hosting.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses_3","title":"Weaknesses","text":"<ul> <li>May lag behind proprietary top-performers on some benchmarks.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_3","title":"Best uses","text":"<ul> <li>Self-hosted assistants, custom fine-tuning on proprietary data, and privacy-sensitive deployments.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_3","title":"Example prompt","text":"<p>\"You are a company-specific assistant. Given this product manual, answer the user's question and cite sections used.\" </p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#mistral","title":"Mistral","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_4","title":"Strengths","text":"<ul> <li>Efficient open-source models with strong performance for their size.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses_4","title":"Weaknesses","text":"<ul> <li>Ecosystem and tooling are newer and still maturing.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_4","title":"Best uses","text":"<ul> <li>Cost-effective inference and on-prem quantized deployments.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_4","title":"Example prompt","text":"<p>\"Generate a 3-paragraph overview of this research paper and list two follow-up experiments.\" </p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#falcon-mpt","title":"Falcon / MPT","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_5","title":"Strengths","text":"<ul> <li>Flexible open models for experimentation and domain-specific fine-tuning.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#weaknesses_5","title":"Weaknesses","text":"<ul> <li>Mixed benchmark results; production readiness may need extra engineering.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_5","title":"Best uses","text":"<ul> <li>Research, domain fine-tuning, and custom workloads where licensing is favorable.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_5","title":"Example prompt","text":"<p>\"Fine-tune this model to perform product categorization; outline a minimal dataset and training plan.\" </p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#cohere-aleph-alpha-and-other-providers","title":"Cohere, Aleph Alpha, and other providers","text":"","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#strengths_6","title":"Strengths","text":"<ul> <li>Provider alternatives with good embeddings, multilingual support, and classification features.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#best-uses_6","title":"Best uses","text":"<ul> <li>Embeddings, multilingual classification, and specialized provider integrations.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#example-prompt_6","title":"Example prompt","text":"<p>\"Return embeddings for these three documents and compute cosine similarities.\"</p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#small-comparison-table","title":"Small comparison table","text":"Model / Provider Strengths Best uses Latency Cost Fine-tuning Self-hostable Notes OpenAI GPT-4 Top accuracy, tooling, plugins Chat, code, RAG gen Medium High Limited (OpenAI fine-tune options) No (API) Excellent for production when budget allows Anthropic Claude Safety, long-dialog handling Support bots, safe assistants Medium Medium-High Vendor fine-tuning No (API) Strong safety posture Google Gemini/PaLM Multimodal, GCP integration Multimodal apps, enterprise Medium High API-based fine-tuning No (API) Great for image+text tasks Meta Llama 2/3 Open weights, self-hosting Fine-tuning, on-prem assistants Variable Low (self-host infra cost) Yes (community tools) Yes Good balance for privacy-focused apps Mistral Efficient, strong open performance Cost-effective inference Low-Medium Low Yes Yes Fast-moving open-source option Falcon / MPT Research &amp; domain fine-tuning Experimentation, edge cases Variable Low Yes Yes Useful for custom workloads Cohere / Aleph Alpha Embeddings &amp; multilingual Embeddings, classification Low-Medium Medium Yes No/limited Provider alternatives with unique strengths <p>Notes: \"Latency\" and \"Cost\" are generalizations \u2014 actual values depend heavily on hosting, model size, and usage pattern.</p>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#choosing-by-task-concise","title":"Choosing by task (concise)","text":"<ul> <li>Chat &amp; reasoning: GPT-4 or Claude 3; self-hosted option \u2014 Llama 3 with RAG.</li> <li>Code assistants: GPT-4 (best), or fine-tuned Llama/Mistral for on-prem.</li> <li>RAG &amp; long-docs: Use models with long-context support or combine embeddings + RAG with a strong generator (GPT, Claude).</li> <li>Cost-sensitive bulk generation: GPT-3.5 or quantized Llama/Mistral/Falcon.</li> <li>Multimodal: Gemini or OpenAI multimodal variants.</li> <li>On-device/privacy: Quantized Llama, Mistral, Falcon with llama.cpp/ggml or vLLM.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#quick-decision-checklist","title":"Quick decision checklist","text":"<ol> <li>Data sensitivity: must data stay on-prem? If yes \u2192 self-host (Llama/Mistral/Falcon).</li> <li>Budget per request: high \u2192 GPT-4; low \u2192 GPT-3.5 or quantized open models.</li> <li>Latency requirements: low-latency \u2192 smaller/quantized models near users.</li> <li>Integration needs: plugins/tools \u2192 OpenAI has richest ecosystem.</li> <li>Multimodal requirements: Gemini or OpenAI multimodal models.</li> <li>Need to fine-tune: prefer open weights (Llama family, Mistral) or providers with fine-tuning APIs.</li> </ol>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#practical-prompts-examples","title":"Practical prompts (examples)","text":"<ul> <li>Summarization: \"Summarize the following text in 5 bullets focusing on action items and risks:\"</li> </ul> <pre><code>The product launch was delayed three weeks due to supplier shortages. The engineering team recommends increasing vendor redundancy and adding a safety stock. Marketing timelines will shift and customer communications must be prepared. The finance team should review budget for expedited shipping options.\n</code></pre> <ul> <li> <p>Classification (few-shot): \"Label the sentiment of these examples (POS/NEG/NEUTRAL). Return JSON array of labels.\"</p> <p>Example (few-shot input):</p> <pre><code>Example 1: \"I love the new update \u2014 the UI is so much cleaner and faster!\"\nExample 2: \"The product crashed three times today. Very disappointing experience.\"\nExample 3: \"The feature works as expected; nothing surprising either way.\"\n</code></pre> <p>Prompt instruction: \"Label the sentiment of the examples above as POS, NEG, or NEUTRAL and return a JSON array of labels in the original order.\"</p> <p>Expected output (example):</p> <pre><code>[\"POS\", \"NEG\", \"NEUTRAL\"]\n</code></pre> </li> <li> <p>RAG assistant: \"Given the retrieved documents below and the user question, provide a concise answer and cite document IDs used.\"</p> <p>Example (retrieved docs + question):</p> <pre><code>[DOC_1] Title: Supplier report\nContent: \"Supplier A reported delays in shipments for component X due to raw material shortages.\"\n\n[DOC_2] Title: Engineering notes\nContent: \"Team recommends increasing vendor redundancy and maintaining a two-week safety stock.\"\n\nUser question: \"Why was the product launch delayed and what should we do next?\"\n</code></pre> <p>Prompt instruction: \"Answer concisely using the retrieved documents. Cite the document IDs (e.g., DOC_1, DOC_2) used for each statement.\"</p> <p>Example expected answer:</p> <pre><code>The launch was delayed due to supplier shortages for component X (DOC_1). Recommended next steps: increase vendor redundancy and maintain a two-week safety stock to mitigate future delays (DOC_2).\n</code></pre> </li> <li> <p>Code explanation: \"Explain the following Python function in simple terms and suggest two tests for edge cases:\"</p> </li> </ul> <pre><code>def is_prime(n):\n    \"\"\"Return True if n is a prime number, otherwise False.\"\"\"\n    if n &lt;= 1:\n        return False\n    i = 2\n    while i * i &lt;= n:\n        if n % i == 0:\n            return False\n        i += 1\n    return True\n</code></pre>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#operational-checklist-engineering","title":"Operational checklist (engineering)","text":"<ul> <li>Start with a small POC to measure latency, cost, and hallucination rates.</li> <li>For self-hosting, test quantized inference on your target hardware before committing to a model.</li> <li>Add monitoring for hallucination, latency, and user satisfaction.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"blogs/llm-guide/#caveats","title":"Caveats","text":"<ul> <li>Hallucination: All LLMs can hallucinate \u2014 use RAG/verification for critical outputs.</li> <li>Safety: Add guardrails and human review for high-risk outputs.</li> <li>Licensing: Check open-model licenses before commercial use.</li> </ul>","tags":["LLM","GPT","Claude","Llama","Mistral","RAG","Fine-tuning"]},{"location":"projects/project_1/","title":"Project 1","text":""},{"location":"projects/project_1/#mkdocs-to-build-the-portfolio","title":"mkdocs to build the portfolio","text":"<p>Details how built </p>"}]}